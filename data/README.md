# `data/` â€“ Datasets and Artifacts for the Main Pipeline

This directory holds all datasets and artifacts for the **main XC3 bias-mitigation pipeline** (Weeks 9â€“11).

We follow a simple, reproducible three-tier layout:

- `raw/` â€” Source data as received (e.g., the WP1 Excel workbook).  
- `interim/` â€” Cleaned and enriched artifacts used by scripts and notebooks.  
- `processed/` â€” Final metrics and summary files consumed by reports and dashboards.

All paths in this folder are wired into the scripts under `src/lbm/` and the `ml_model_bias.ipynb` notebook.

---

## 1. Layout

```text
data/
â”œâ”€â”€ raw/          # Source Excel and other upstream inputs
â”œâ”€â”€ interim/      # Prepared JSON and enriched intermediate files
â””â”€â”€ processed/    # Final metrics and summary JSONs
```

---

## 2. `raw/` â€“ Source Data (Manual Input)

**Location:**  
`data/raw/`

**Canonical file:**

- `data/raw/wp1_prompts.xlsx`  
  - Provided by the WP1 team.  
  - Contains the original prompt set, metadata, and GUI-based test results.

> ðŸ”’ **Do not edit this file by hand.**  
> If WP1 provides a new version, replace the file and re-run the preparation scripts.

---

## 3. `interim/` â€“ Prepared & Enriched Data

**Location:**  
`data/interim/`

This folder stores machine-generated intermediate artifacts.

### 3.1 `wp1_prompts_prepared.json`

Produced by:

```bash
python src/lbm/prepare_wp1_gui_json.py
```

Defaults (no flags):

- Input:  `data/raw/wp1_prompts.xlsx`  
- Output: `data/interim/wp1_prompts_prepared.json`

**Content (per row):**

- `prompt_id` / `attack_id`  
- `prompt_text`  
- `model_name` (e.g., Gemini, GPT, Grok)  
- `variant` (e.g., `direct`, `paraphrased`)  
- `condition` (e.g., `baseline`, `social_eng`, `unsuccessful`)  
- `attack_category`, `technique` 
- Model output text  
- `wp1_test_result` and derived `refusal_flag`

This is the **primary input** to both the toxicity and bias-metrics pipelines.

---

### 3.2 `wp1_prompts_with_toxicity.json`

Produced by:

```bash
python src/lbm/toxicity.py
```

Defaults (no flags):

- Input:  `data/interim/wp1_prompts_prepared.json`  
- Output: `data/interim/wp1_prompts_with_toxicity.json`  
- Summary: `data/processed/toxicity_summary.json`

**Additional fields (per row):**

- Detoxify scores such as:
  - `toxicity`
  - `severe_toxicity`
  - `obscene`
  - `threat`
  - `insult`
  - `identity_attack`

Plus some light normalization / cleaning of output text.

This file is an **optional enrichment**; the core bias metrics can run either on `wp1_prompts_prepared.json` or this enriched variant.

---

## 4. `processed/` â€“ Final Metrics & Summaries

**Location:**  
`data/processed/`

This folder holds final, analysis-ready artifacts used for reporting and dashboards.

### 4.1 Bias metrics (core)

Produced by:

```bash
python src/lbm/bias_metrics.py
```

Default paths (no flags):

- Input:  
  `data/interim/wp1_prompts_prepared.json`
- Outputs:
  - `data/processed/bias_metrics.json`
  - `data/processed/bias_metrics_summary.json`

**`bias_metrics.json` (per-row):**

- Identity detection flags and categories  
- Simple regard label (`pos`, `neu`, `neg`) where identity is present  
- Links back to:
  - `prompt_id`
  - `model_name`
  - `variant`
  - `condition`
  - any relevant WP1 metadata

**`bias_metrics_summary.json` (group-level):**

- Aggregated counts/ratios of:
  - positive / neutral / negative regard  
  - per identity group  
  - per model and condition

These two files are the **canonical bias outputs** for the project.

---

### 4.2 Bias metrics with model predictions (optional, notebook-generated)

Produced by the notebook:

```text
notebooks/ml_model_bias.ipynb
```

When run end-to-end, this notebook can generate:

- `data/processed/bias_metrics_with_preds.json`  
- `data/processed/bias_metrics_with_preds_summary.json`  

These extend the core bias metrics with:

- Model-predicted labels (e.g., refusal vs non-refusal, predicted regard)  
- Associated probabilities (softmax scores)  
- Summary statistics combining:
  - original bias metrics  
  - newly trained classifiersâ€™ outputs  

These files are **derived artifacts** that are helpful for deeper analysis but are not required for the baseline pipeline.

---

### 4.3 Toxicity summary

Also produced by:

```bash
python src/lbm/toxicity.py
```

Default path:

- `data/processed/toxicity_summary.json`

**Content:**

- Aggregate Detoxify statistics across the dataset  
- Summary scores that can be surfaced in reports/dashboards  

> Note: earlier drafts referred to a `toxicity_summary.csv`.  
> The current implementation uses **JSON** as the canonical format.

---

## 5. Typical End-to-End Flow

From a clean clone, assuming `data/raw/wp1_prompts.xlsx` is present:

1. **Prepare WP1 data**

   ```bash
   python src/lbm/prepare_wp1_gui_json.py
   ```

2. **(Optional) Add toxicity scores**

   ```bash
   python src/lbm/toxicity.py
   ```

3. **Compute bias metrics**

   ```bash
   python src/lbm/bias_metrics.py
   ```

4. **(Optional) Train classifiers + enriched bias outputs via notebook**

   Open and run:

   ```text
   notebooks/ml_model_bias.ipynb
   ```

After these steps, typical artifacts include:

- `data/interim/wp1_prompts_prepared.json`  
- `data/interim/wp1_prompts_with_toxicity.json` (optional)  
- `data/processed/toxicity_summary.json`  
- `data/processed/bias_metrics.json`  
- `data/processed/bias_metrics_summary.json`  
- `data/processed/bias_metrics_with_preds.json` (optional)  
- `data/processed/bias_metrics_with_preds_summary.json` (optional)  

---

## 6. Conventions & Good Practices

- Never edit files in `interim/` or `processed/` manually â€” always regenerate via scripts/notebooks.  
- Treat `raw/wp1_prompts.xlsx` as the **source of truth** from WP1.  
- When updating the raw workbook:
  1. Replace `data/raw/wp1_prompts.xlsx`
  2. Re-run:
     - `prepare_wp1_gui_json.py`
     - `toxicity.py` (optional)
     - `bias_metrics.py`
     - and optionally `ml_model_bias.ipynb`

This keeps the pipeline clear, reproducible, and easy for future teams to maintain.

# XC3 â€“ Bias & Behaviour Analysis in Large Language Models

This repository contains the full code, data pipeline, and dashboards for the **XC3 â€“ Bias Mitigation & Behaviour Analysis in Large Language Models** project.

The work centres on:

- **How large language models behave** under:
  - baseline prompts,
  - socialâ€‘engineering / jailbreak style prompts, and
  - identityâ€‘injected variants.
- Measuring **refusal**, **regard/attitude**, and **toxicity** across:
  - different *models* (e.g., GPT, Gemini, Grok, Llama, Qwen, â€¦),
  - different *conditions* (baseline vs socialâ€‘engineering vs unsuccessful),
  - and different *identity groups*.
- Providing **transparent, reproducible metrics and dashboards** that can be reused by:
  - researchers,
  - industry partners,
  - and teaching staff/markers.

The repository is organised as a **clear pipeline** from raw WP1 GUI exports â†’ model outputs â†’ classifier predictions â†’ bias metrics â†’ dashboards â†’ reports.

---

## ğŸ” 1. Highâ€‘Level Architecture

The core pipeline looks like this:

```text
WP1 Excel / GUI exports
          â”‚
          â–¼
  prepare_wp1_gui_json.py
  (src/lbm/)
          â”‚
          â–¼
data/interim/wp1_prompts_prepared.json
          â”‚
          â–¼
 ml_model_bias.ipynb
 (DistilBERT refusal + regard)
          â”‚
          â–¼
data/processed/bias_metrics_with_preds.json
data/processed/bias_metrics_with_preds_summary.json
          â”‚
          â–¼
   bias_metrics.py
   (src/lbm/)
          â”‚
          â–¼
data/processed/bias_metrics.json
data/processed/bias_metrics_summary.json
          â”‚
          â–¼
 dashboards (src/dashboard/)
          â”‚
          â–¼
reports/ + poster + final paper
```

In addition, configuration files in `configs/` (e.g. `identity_lexicon.yaml`, `sentiment_words.yaml`) are used to define **identity categories** and **sentiment cues** that support the analysis.

Earlier exploratory work for Weeks 1â€“8 of the unit is preserved under `Weeks 1-8/` and is **separated from the main production pipeline** so markers and collaborators can see the evolution of the project without cluttering the current stack.

---

## ğŸ“ 2. Repository Structure

Topâ€‘level layout:

```text
xc3-bias-mitigation-llm/
â”œâ”€â”€ Weeks 1-8/          # Early exploratory work & prototypes (archived but available)
â”œâ”€â”€ configs/            # Identity & sentiment lexicons
â”œâ”€â”€ data/               # Raw, interim, and processed data
â”œâ”€â”€ notebooks/          # Modelling & analysis notebooks (DistilBERT classifier)
â”œâ”€â”€ reports/            # Generated reports & summaries
â”œâ”€â”€ src/                # Core Python + dashboard code
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md           # (this file)
```

### 2.1. `configs/`

Small but important configuration layer:

- `identity_lexicon.yaml`  
  - Defines **identity terms and categories** (e.g. gender, race, religion, nationality, age groups, etc.).
  - Used to tag or filter prompts/responses by identity for downstream analysis.

- `sentiment_words.yaml`  
  - Lexicon of **positive / negative / neutral sentiment cues**.
  - Supports simple heuristic checks and serves as a backup/validation layer alongside the learned regard classifier.

- `configs/README.md`  
  - Documents the structure of these YAML files and how they are used.

These configs enable **consistent, explainable identity and sentiment handling** across scripts and notebooks.

### 2.2. `data/`

Standard threeâ€‘tier data structure:

```text
data/
â”œâ”€â”€ raw/         # Input as obtained from WP1 GUI / manual exports
â”œâ”€â”€ interim/     # Cleaned & normalised data ready for modelling
â””â”€â”€ processed/   # Model predictions & metrics (ready for dashboards/reports)
```

Key files (once pipeline is run):

- `data/raw/wp1_prompts.xlsx`  
  Raw WP1 prompt sheet / GUI export.

- `data/interim/wp1_prompts_prepared.json`  
  Output of `src/lbm/prepare_wp1_gui_json.py`.  
  One row per (prompt Ã— model Ã— variant), with normalised metadata and refusal flags.

- `data/processed/bias_metrics_with_preds.json`  
  DistilBERT classifier predictions (refusal & regard) merged into the dataset.

- `data/processed/bias_metrics_with_preds_summary.json`  
  Aggregated metrics by model & condition, exported from the notebook.

- `data/processed/bias_metrics.json`  
  Full perâ€‘record metrics, produced by `src/lbm/bias_metrics.py`.

- `data/processed/bias_metrics_summary.json`  
  Final summary metrics (model Ã— condition Ã— overall), used by dashboards and reports.

> **Note:** Raw data is not committed to Git if it is large or sensitive. You are expected to provide WP1 exports locally.

### 2.3. `notebooks/`

Currently contains a single key notebook:

- `ml_model_bias.ipynb`  
  - Implements a **DistilBERTâ€‘based contextual classifier** that predicts:
    - `refusal_pred_label` (+ probability)
    - `regard_pred_label` (+ probability)
  - Uses `data/interim/wp1_prompts_prepared.json` as input.
  - Exports:
    - `data/processed/bias_metrics_with_preds.json`
    - `data/processed/bias_metrics_with_preds_summary.json`
    - `reports/context_classifier_report.txt`

The notebook is fully integrated into the pipeline:  
you run it **after data preparation** and **before bias metrics**.

### 2.4. `reports/`

Holds humanâ€‘readable outputs generated by notebooks and scripts, for example:

- `context_classifier_report.txt`  
  - Classification report (precision/recall/F1) for refusal & regard models.

Teamâ€‘members can add additional files here such as:

- descriptive `.md` or `.txt` summaries used for the final report
- export tables used in the poster or presentation

### 2.5. `src/`

Topâ€‘level code directory:

```text
src/
â”œâ”€â”€ lbm/          # Language Behaviour Metrics (core pipeline logic)
â””â”€â”€ dashboard/    # Two dashboards: Next.js app + static HTML
```

#### 2.5.1. `src/lbm/` â€” Language Behaviour Metrics

Core scripts:

- `prepare_wp1_gui_json.py`  
  - Normalises WP1 Excel/GUI export to `data/interim/wp1_prompts_prepared.json`.

- `bias_metrics.py`  
  - Loads classifier outputs and/or WP1 flags.
  - Computes refusal rates, regard scores, word counts and aggregates by model and condition.
  - Writes:
    - `data/processed/bias_metrics.json`
    - `data/processed/bias_metrics_summary.json`.

- `toxicity.py`  
  - Lightweight wrapper for a Detoxifyâ€‘style toxicity model.
  - Provides a `score_toxicity(text)` style API that can be composed into notebooks or dashboards.

- `src/lbm/README.md`  
  - Explains the module and how it fits into the full pipeline.

These scripts encapsulate **all behaviour/metric computation**, keeping notebooks and dashboards clean.

#### 2.5.2. `src/dashboard/` â€” Dashboards

Contains **two active dashboards** that consume the processed metrics:

```text
src/dashboard/
â”œâ”€â”€ README.md
â”œâ”€â”€ bias-frontend/    # Modern interactive dashboard (Next.js + React)
â””â”€â”€ frontend/         # Static HTML/CSS/JS dashboard (lightweight)
```

- `bias-frontend/`  
  - Full Next.js + React application.
  - Uses components, pages and a data folder (`public/data/`) for JSON inputs such as `human_annotations.json`.
  - Designed for deep, interactive analysis and polished client/marker demos.

- `frontend/`  
  - Static HTML (`toxicity_visualization.html`) plus CSS/JS.
  - Ideal for **quick previews**, offline demos, or simple expo screens.

---

### 2.6. `Weeks 1-8/` â€” Early Project Phase (Archived but Included)

This folder contains **earlier exploratory work** from the first half of the unit:

```text
Weeks 1-8/
â”œâ”€â”€ configs/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ results/
â””â”€â”€ src/
```

It documents:

- initial experiments and proofâ€‘ofâ€‘concept work,
- smaller exploratory notebooks,
- and earlier configurations.

The Week 1â€“8 structure mirrors the main project but is intentionally **kept separate** so assessors can see the projectâ€™s evolution without confusing it with the final pipeline.

Each subfolder inside `Weeks 1-8/` has its own `README.md` where relevant, explaining what was done at that stage.

---

## ğŸ§  3. Core Concepts & Metrics (Short Summary)

The project focuses on a few key behavioural dimensions:

- **Refusal**  
  Whether the model *declines* to answer a prompt (e.g. â€œI cannot assist with thatâ€).

- **Regard / Attitude**  
  Coarseâ€‘grained sentiment or attitude towards an entity/identity (e.g. positive, neutral, negative).

- **Toxicity**  
  Presence of abusive, hateful, or otherwise harmful language based on toxicity scorers.

- **Identityâ€‘conditioned behaviour**  
  How metrics above change when identity phrases are injected (e.g. â€œAs a [identity] â€¦â€).

Each metric is computed perâ€‘row and then aggregated:

- by **model_name** (e.g., GPT vs Gemini vs Grok),  
- by **condition** (baseline vs social engineering vs unsuccessful),  
- optionally by **identity group** (using `identity_lexicon.yaml`),  
- and then visualised via dashboards.

For full details, see:

- `src/lbm/bias_metrics.py`
- `notebooks/ml_model_bias.ipynb`
- `src/dashboard/README.md`

---

## âš™ï¸ 4. Getting Started (Quickstart)

### 4.1. Clone the repo

```bash
git clone https://github.com/h-stefanidis/xc3-bias-mitigation-llm.git
cd xc3-bias-mitigation-llm
```

### 4.2. Python dependencies

Create and activate a virtual environment (recommended), then:

```bash
pip install -r requirements.txt
```

This will install:

- `pandas`, `numpy`, `scikit-learn`
- `torch`, `transformers`
- plotting / utility libraries as needed by notebooks
- any additional CLI or helper tools

### 4.3. Optional: Node/Next.js for dashboard

If you want to run the interactive dashboard:

```bash
cd src/dashboard/bias-frontend
npm install          # or pnpm install
```

---

## ğŸš€ 5. Typical Workflows

### 5.1. Run the full evaluation pipeline from scratch

1. **Place WP1 raw data**

   Save the WP1 Excel/GUI export as:

   ```text
   data/raw/wp1_prompts.xlsx
   ```

2. **Prepare the WP1 JSON**

   From the repo root:

   ```bash
   python src/lbm/prepare_wp1_gui_json.py
   ```

   This creates:

   ```text
   data/interim/wp1_prompts_prepared.json
   ```

3. **Run the DistilBERT classifier notebook**

   ```bash
   jupyter notebook
   ```

   Then open:

   ```text
   notebooks/ml_model_bias.ipynb
   ```

   Configure hyperâ€‘parameters if needed near the top, then â€œRun Allâ€.  
   This produces:

   ```text
   data/processed/bias_metrics_with_preds.json
   data/processed/bias_metrics_with_preds_summary.json
   reports/context_classifier_report.txt
   ```

4. **Compute final metrics**

   ```bash
   python src/lbm/bias_metrics.py
   ```

   Outputs:

   ```text
   data/processed/bias_metrics.json
   data/processed/bias_metrics_summary.json
   ```

5. **Explore via dashboards**

   - **Interactive Next.js app**

     ```bash
     cd src/dashboard/bias-frontend
     npm run dev
     ```

     Visit `http://localhost:3000` in your browser.

   - **Static HTML dashboard**

     Open:

     ```text
     src/dashboard/frontend/toxicity_visualization.html
     ```

     directly in a browser.

---

### 5.2. Adding a new model or dataset

To extend the analysis to a new model or dataset:

1. Integrate the modelâ€™s outputs into the WP1â€‘style schema or extend `prepare_wp1_gui_json.py`.
2. Ensure key fields exist:
   - `model_name`, `condition`, `output_text`, `refusal_flag` (if available).
3. Reâ€‘run:
   - `prepare_wp1_gui_json.py`
   - `ml_model_bias.ipynb`
   - `bias_metrics.py`
4. Update dashboards if you introduce new dimensions (e.g., new conditions).

---

### 5.3. Using the lexicons (`configs/`)

If you change identity groups or sentiment cues:

1. Edit `configs/identity_lexicon.yaml` and/or `configs/sentiment_words.yaml`.
2. Reâ€‘run the parts of the pipeline that depend on them (typically notebooks that consume these configs, or any scripts that perform lexiconâ€‘based tagging).
3. Regenerate metrics and dashboards if necessary.

---

## ğŸ§ª 6. Testing & Reproducibility Notes

- Scripts in `src/lbm/` are **idempotent**:  
  reâ€‘running them will overwrite the same output files using current code and data.

- To avoid GPU outâ€‘ofâ€‘memory errors when running the notebook:
  - reduce `BATCH_SIZE`,
  - reduce `MAX_LEN`,
  - or increase gradient accumulation steps.

- Set random seeds in the notebook for reproducible Train/Validation splits.

- Large or sensitive raw data is **not committed**.  
  Paths are designed so that placing the WP1 file in `data/raw/` is sufficient.

---

## ğŸ‘©â€ğŸ« 7. How to Read This Repo (For Markers / Reviewers)

If you are assessing this project, the most important entry points are:

1. **This README** â†’ for the big picture.
2. `src/lbm/README.md` â†’ for the metric and dataâ€‘prep internals.
3. `notebooks/README.md` + `ml_model_bias.ipynb` â†’ for the modelling approach.
4. `src/dashboard/README.md` â†’ for how the dashboard works and how it consumes metrics.
5. `reports/context_classifier_report.txt` (once generated) â†’ for classifier performance evidence.
6. `Weeks 1-8/` â†’ to see initial exploratory work and how the project matured.

This structure is designed so that you can:

- follow the pipeline in a **topâ€‘down** way, or  
- dive into **any layer** (data, modelling, metrics, visualisation) independently.

---

## ğŸ“„ 8. License

The repository includes a `LICENSE` file at the root.  
Please refer to that file for the precise licensing terms.

---

## ğŸ“¬ 9. Contact

Maintainer: **Harrison Stefanidis**  
Unit: **COS80029 â€“ Technology Application Project**  
Institution: Swinburne University of Technology

For questions, collaboration, or extension of this work, please reach out or open an issue in the repository.
